{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7919927b",
   "metadata": {},
   "source": [
    "## Directory structure\n",
    "```bash\n",
    "aiffel\n",
    "└── transformer_chatbot\n",
    "    ├── project16.ipynb      <─ I am here\n",
    "    └── data\n",
    "        └── ChatbotData.csv  \n",
    "```\n",
    "\n",
    "\n",
    "## ChatbotData.csv 내용\n",
    "![](https://github.com/songys/Chatbot_data/raw/master/data.png)\n",
    "\n",
    "- 챗봇 트레이닝용 문답페어 11,876개\n",
    "- label : 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad5c80",
   "metadata": {},
   "source": [
    "## Step1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bb89f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원천 데이터 불러오기 완료 \n",
      "총 길이 : 11823\n",
      "---<각 컬럼별 결측치 개수 확인>---\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source_data = pd.read_csv('data/ChatbotData.csv')\n",
    "print(f\"원천 데이터 불러오기 완료 \\n총 길이 : {len(source_data)}\")\n",
    "print(\"---<각 컬럼별 결측치 개수 확인>---\")\n",
    "print(source_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf7d94",
   "metadata": {},
   "source": [
    "## Step2. 데이터 전처리하기\n",
    "\n",
    "`Step1`에서 각 컬럼별 __결측치가 없으므로__ 전처리 단계에서는 `-`정도만 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76077669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    #단어와 특수문자 사이의 거리를 만든다.\n",
    "    #Before: \"12시 땡!\"\n",
    "    #After : \"12시 땡 ! \"\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3deadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chat():\n",
    "    questions, answers = [], []\n",
    "    _question, _answer = list(source_data['Q']), list(source_data['A'])\n",
    "    \n",
    "    for i in range(len(source_data)):\n",
    "        questions.append(preprocess_sentence(_question[i]))\n",
    "        answers.append(preprocess_sentence(_answer[i]))\n",
    "        \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab0b0b",
   "metadata": {},
   "source": [
    "### Q컬럼과 A컬럼 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ace4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 ! ', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 . ', '위로해 드립니다 . ', '여행은 언제나 좋죠 . ', '여행은 언제나 좋죠 . ', '눈살이 찌푸려지죠 . ']\n",
      "question 전체 길이 : 11823\n",
      "answer   전체 길이 : 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_chat()\n",
    "print(f\"{questions[:5]}\")\n",
    "print(f\"{answers[:5]}\")\n",
    "print(f\"question 전체 길이 : {len(questions)}\\nanswer   전체 길이 : {len(answers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce59b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qestion의 최소 길이 : 1\n",
      "Qestion의 최대 길이 : 15\n",
      "Qestion의 평균 길이 : 3.587414361837097\n",
      "Answer의 최소 길이 : 1\n",
      "Answer의 최대 길이 : 21\n",
      "Answer의 평균 길이 : 3.6936479742874058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe0UlEQVR4nO3deZRdZZ3u8e9DGBU0YEoMBAxIHHCKGAaV9qIIhqFFeymCAxHRtF4U7ItD0L6CA1dsbVAcUBAkKkKzUNs0pIGIII0KJIFACEiThiCJAQLIENBIwnP/2G/JsaiqvZPUqXMq9XzW2uvs/e7pdzLUr95hv1u2iYiIGMxGnQ4gIiK6X5JFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkEdEFJL1b0mWdjiNiIEkWMepJep+khZIel3SPpG9LenYb7zdRkiVt3Ftm+1zb+7frnhHrK8kiRjVJxwFfBj4BPBvYC5gIXCZpkw6GFtFVkixi1JL0LOBzwEdtX2L7CdtLgEOBnYF3STpH0hdbztlH0tKW7e0k/UTSCkl3SjqmZd8ekuZJekTSvZJOKbuuKp8PSVop6TWldnN1y7mvlTRX0sPl87Ut+66U9AVJv5b0qKTLJI0r+zaX9CNJD0h6qJy77dD/6cVok2QRo9lrgc2Bn7YW2l4JzAYGbRaStBHwH8CNwPbAvsDHJL25HPJ14Ou2nwW8ALiglL++fI61vaXt3/a57jbAxcBpwHOAU4CLJT2n5bB3AUcCzwU2BT5eyqdR1ZB2KOd+CPjToH8KEQ0kWcRoNg643/bqfvYtB3pqzt8d6LH9edt/sX0HcCZwWNn/BLCLpHG2V9q+pmFcBwG32/6h7dW2zwN+B/x9yzHft/3ftv9ElYQmt9zzOcAuttfYnm/7kYb3jRhQkkWMZvcD41o7mluML/sH83xgu9Lc85Ckh4BPA73NPkcBLwR+V5qDDm4Y13bAXX3K7qKqvfS6p2X9cWDLsv5D4FLgfEl/kPQv6XuJoZBkEaPZb4FVwD+0FkraEjgAuBJ4DHhGy+7ntazfDdxpe2zLspXtAwFs3277cKqmoi8DF0p6JlD3XoA/UCWiVjsCy+q+UOl3+ZztXama2Q4Gjqg7L6JOkkWMWrYfpurg/oakqZI2kTSRqlnnfuBcYAFwoKRtJD0P+FjLJa4DHpX0KUlbSBoj6WWSdgeQ9B5JPbafBB4q5zwJrCifOw8Q2mzghZLeJWljSe8EdgUuqvtOkt4g6eWSxgCPUDVLPdn0zyRiIEkWMarZ/heqpqOvAo8Cd1LVJN5k+zGqZp0bgSXAZcC/tZy7huo398nlvPuB71F1MANMBRZJWknV2X2Y7T/Zfhw4Cfh1ab7aq09MD5TrHgc8AHwSONh2XbMYVDWfC6kSxa3Ar8p3iFgvypvyIp4i6Ujg88DrbP++0/FEdIski4g+JL0XeML2+Z2OJaJbtK0ZqjwcdJ2kGyUtkvS5Un5OeXhpQVkml3JJOk3SYkk3Sdqt5VrTJN1elmntijkCoAxZTaKIaNHfkMGhsgp4o+2VZeje1ZL+s+z7hO0L+xx/ADCpLHsCpwN7lgeUTgCmUI0imS9plu0/tjH2iIho0bZk4ap9a2XZ3KQsg7V5HQL8oJx3jaSxksYD+wBzbD8IIGkOVcfheQNdaNy4cZ44ceJ6f4eIiNFk/vz599vu92HUdtYsKMP35gO7AN+yfa2kDwMnSfoscDkww/YqqgeO7m45fWkpG6i8772mA9MBdtxxR+bNm9eGbxQRseGS1Pdh0L9q69DZMt3AZGACsIeklwHHAy+mmiphG+BTQ3SvM2xPsT2lp6duloaIiFgbw/Kche2HgCuAqbaXu7IK+D6wRzlsGdXkZ70mlLKByiMiYpi0czRUj6SxZX0LYD+qOXLGlzIBbwVuLqfMAo4oo6L2Ah62vZxqnpv9JW0taWuqmUAvbVfcERHxdO3ssxgPzCz9FhsBF9i+SNIvJfUAoppK4UPl+NnAgcBiqonRjgSw/aCkLwBzy3Gf7+3sjoiI4bFBPpQ3ZcoUp4M7ImLtSJpve0p/+zI3VERE1EqyiIiIWkkWERFRK8kiIiJqtfUJ7hhaE2dcPOC+JScfNIyRRMRok5pFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtZIsIiKiVpJFRETUaluykLS5pOsk3ShpkaTPlfKdJF0rabGkf5O0aSnfrGwvLvsntlzr+FJ+m6Q3tyvmiIjoXztrFquAN9p+JTAZmCppL+DLwKm2dwH+CBxVjj8K+GMpP7Uch6RdgcOAlwJTgW9LGtPGuCMioo+2JQtXVpbNTcpi4I3AhaV8JvDWsn5I2abs31eSSvn5tlfZvhNYDOzRrrgjIuLp2tpnIWmMpAXAfcAc4H+Ah2yvLocsBbYv69sDdwOU/Q8Dz2kt7+ec1ntNlzRP0rwVK1a04dtERIxebU0WttfYngxMoKoNvLiN9zrD9hTbU3p6etp1m4iIUWlYRkPZfgi4AngNMFbSxmXXBGBZWV8G7ABQ9j8beKC1vJ9zIiJiGLRzNFSPpLFlfQtgP+BWqqTx9nLYNODnZX1W2abs/6Vtl/LDymipnYBJwHXtijsiIp5u4/pD1tl4YGYZubQRcIHtiyTdApwv6YvADcBZ5fizgB9KWgw8SDUCCtuLJF0A3AKsBo62vaaNcUdERB9tSxa2bwJe1U/5HfQzmsn2n4F3DHCtk4CThjrGiIhoJk9wR0RErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFptSxaSdpB0haRbJC2SdGwpP1HSMkkLynJgyznHS1os6TZJb24pn1rKFkua0a6YIyKifxu38dqrgeNsXy9pK2C+pDll36m2v9p6sKRdgcOAlwLbAb+Q9MKy+1vAfsBSYK6kWbZvaWPsERHRom3JwvZyYHlZf1TSrcD2g5xyCHC+7VXAnZIWA3uUfYtt3wEg6fxybJLFEJo44+IB9y05+aBhjCQiulFtspD0DuCS8gP/n4HdgC/avr7pTSRNBF4FXAu8DviIpCOAeVS1jz9SJZJrWk5bylPJ5e4+5Xv2c4/pwHSAHXfcsWloQy4/dCNiQ9Skz+L/lkSxN/Am4Czg9KY3kLQl8BPgY7YfKee+AJhMVfP417UNuj+2z7A9xfaUnp6eobhkREQUTZLFmvJ5EHCG7YuBTZtcXNImVIniXNs/BbB9r+01tp8EzuSppqZlwA4tp08oZQOVR0TEMGmSLJZJ+i7wTmC2pM2anCdJVLWQW22f0lI+vuWwtwE3l/VZwGGSNpO0EzAJuA6YC0yStJOkTak6wWc1iDsiIoZIkw7uQ4GpwFdtP1R+2H+iwXmvA94LLJS0oJR9Gjhc0mTAwBLgHwFsL5J0AVXH9WrgaNtrACR9BLgUGAOcbXtRo28XERFDojZZ2H5c0n3A3sDtVD/Ib29w3tWA+tk1e5BzTgJO6qd89mDnRUREezVpTjoB+BRwfCnaBPhRO4OKiIju0qTP4m3AW4DHAGz/AdiqnUFFRER3aZIs/mLbVH0MSHpme0OKiIhu0yRZXFBGQ42V9EHgF1RDXiMiYpRo0sH9VUn7AY8ALwI+a3tOzWkREbEBaTQ3VEkOSRAREaPUgMlC0qOUfoq+uwDbflbbooqIiK4yYLKwnRFPEREBNGyGkrQb1UN5Bq62fUNbo4qIiK7S5KG8zwIzgecA44BzylTlERExSjSpWbwbeKXtPwNIOhlYAHyxjXFFREQXafKcxR+AzVu2NyNThEdEjCpNahYPA4vK+7NN9S7s6ySdBmD7mDbGFxERXaBJsvhZWXpd2Z5QIiKiWzV5gnvmcAQSERHdq8loqIMl3SDpQUmPSHpU0iPDEVxERHSHJs1QXwP+AVhYZp+NiIhRpsloqLuBm5MoIiJGryY1i08CsyX9CljVW2j7lLZFFRERXaVJsjgJWEn1rMWm7Q0nIiK6UZNksZ3tl7U9koiI6FpN+ixmS9q/7ZFERETXapIsPgxcIulPazN0VtIOkq6QdIukRZKOLeXbSJoj6fbyuXUpl6TTJC2WdFOZ6bb3WtPK8bdLmrauXzYiItZNbbKwvZXtjWxvYftZZbvJi49WA8fZ3hXYCzha0q7ADOBy25OAy8s2wAHApLJMB06HKrkAJwB7AnsAJ/QmmIiIGB5N32exNdUP8b9OKGj7qsHOsb0cWF7WH5V0K7A9cAiwTzlsJtX0IZ8q5T8oQ3SvkTRW0vhy7BzbD5ZY5gBTgfMafcOIiFhvtclC0geAY4EJVFOT7wX8Fnhj05tImgi8CrgW2LYkEoB7gG3L+vZUz3T0WlrKBirve4/pVDUSdtxxx6ahRUREA036LI4Fdgfusv0Gqh/6DzW9gaQtgZ8AH7P9N30dpRYxJA/72T7D9hTbU3p6eobikhERUTRJFn9uefHRZrZ/B7yoycUlbUKVKM61/dNSfG9pXqJ83lfKlwE7tJw+oZQNVB4REcOkSbJYKmks8O/AHEk/B+6qO0mSgLOAW/s87T0L6B3RNA34eUv5EWVU1F7Aw6W56lJgf0lbl76T/UtZREQMkyZTlL+trJ4o6Qrg2cAlDa79OuC9wEJJC0rZp4GTgQskHUWVdA4t+2YDBwKLgceBI8v9H5T0BWBuOe7zvZ3dERExPJp0cL8AWGp7FSBgIvAM4C+DnWf76nJ8f/bt53gDRw9wrbOBs+tijYiI9mjSDPUTYI2kXYAzqPoPftzWqCIioqs0SRZP2l4NvA34hu1PAOPbG1ZERHSTJsniCUmHU3VGX1TKNmlfSBER0W2aJIsjgdcAJ9m+U9JOwA/bG1ZERHSTJqOhbgGOadm+E/hyO4OKiIju0qRmERERo1ySRURE1BowWUj6Yfk8dvjCiYiIbjRYzeLVkrYD3l+m2timdRmuACMiovMG6+D+DtXLiXYG5vO3T2O7lEdExCgwYM3C9mm2XwKcbXtn2zu1LEkUERGjSJOhsx+W9Erg70rRVbZvam9YERHRTWpHQ0k6BjgXeG5ZzpX00XYHFhER3aPJO7g/AOxp+zEASV+meq3qN9oZWEREdI8mz1kIWNOyvYaBpx6PiIgNUJOaxfeBayX9rGy/leoNeBERMUo06eA+RdKVwN6l6EjbN7Q1qoiI6CpNahbYvh64vs2xREREl8rcUBERUSvJIiIiag2aLCSNkXTFcAUTERHdadBkYXsN8KSkZw9TPBER0YWaNEOtBBZKOkvSab1L3UmSzpZ0n6SbW8pOlLRM0oKyHNiy73hJiyXdJunNLeVTS9liSTPW9gtGRMT6azIa6qdlWVvnAN8EftCn/FTbX20tkLQrcBjwUmA74BeSXlh2fwvYD1gKzJU0q7zqNSIihkmT5yxmStoC2NH2bU0vbPsqSRMbHn4IcL7tVcCdkhYDe5R9i23fASDp/HJskkVExDBqMpHg3wMLgEvK9mRJs9bjnh+RdFNpptq6lG0P3N1yzNJSNlB5f3FOlzRP0rwVK1asR3gREdFXkz6LE6l+y38IwPYC1v3FR6cDLwAmA8uBf13H6zyN7TNsT7E9paenZ6guGxERNOuzeML2w9LfzB345LrczPa9veuSzgQuKpvLgB1aDp1QyhikPCIihkmTZLFI0ruAMZImAccAv1mXm0kab3t52Xwb0DtSahbwY0mnUHVwTwKuo5rddpKknaiSxGHAu9bl3tEZE2dcPOj+JScfNEyRRMT6aJIsPgp8BlgFnAdcCnyh7iRJ5wH7AOMkLQVOAPaRNJnqHd5LgH8EsL1I0gVUHdergaPLMx5I+ki55xiqV7wuav71IiJiKDQZDfU48Jny0iPbfrTJhW0f3k/xgFOb2z4JOKmf8tnA7Cb3jIiI9mgyGmp3SQuBm6gezrtR0qvbH1pERHSLJs1QZwH/2/Z/AUjam+qFSK9oZ2AREdE9mgydXdObKABsX03VrxAREaPEgDULSbuV1V9J+i5V57aBdwJXtj+0iIjoFoM1Q/V9YO6ElnW3IZaIiOhSAyYL228YzkAiIqJ71XZwSxoLHAFMbD3e9jFtiyoiIrpKk9FQs4FrgIWs4zQfERExsjVJFpvb/j9tjyQiIrpWk6GzP5T0QUnjJW3Tu7Q9soiI6BpNahZ/Ab5CNT9U7ygos+7TlEdExAjTJFkcB+xi+/52BxMREd2pSTPUYuDxdgcSERHdq0nN4jFggaQrqKYpBzJ0NiJiNGmSLP69LBERMUo1eZ/FzOEIJCIiuleTJ7jvpJ+5oGxnNFRExCjRpBlqSsv65sA7gDxnERExitSOhrL9QMuyzPbXgIPaH1pERHSLJs1Qu7VsbkRV02hSI4mIiA1Ekx/6re+1WA0sAQ5tSzQREdGVmoyGynstIiJGudo+C0mbSXqXpE9L+mzv0uC8syXdJ+nmlrJtJM2RdHv53LqUS9JpkhZLuqm16UvStHL87ZKmresXjYiIdddkuo+fA4dQNUE91rLUOQeY2qdsBnC57UnA5WUb4ABgUlmmA6dDlVyoXue6J7AHcEJvgomIiOHTpM9igu2+P/Rr2b5K0sQ+xYcA+5T1mcCVwKdK+Q9sG7hG0lhJ48uxc2w/CCBpDlUCOm9t44mIiHXXpGbxG0kvH6L7bWt7eVm/B9i2rG8P3N1y3NJSNlD500iaLmmepHkrVqwYonAjIgKaJYu9gfmSbiv9CQsl3bS+Ny61iKc9Gb4e1zvD9hTbU3p6eobqshERQbNmqAOG8H73Shpve3lpZrqvlC8Ddmg5bkIpW8ZTzVa95VcOYTwREdFAkye47+pvWcf7zQJ6RzRNo+o87y0/ooyK2gt4uDRXXQrsL2nr0rG9fymLiIhh1LYnsSWdR1UrGCdpKdWoppOBCyQdBdzFUw/3zQYO5KkXLR0JYPtBSV8A5pbjPt/b2R0REcOnbcnC9uED7Nq3n2MNHD3Adc4Gzh7C0CIiYi016eCOiIhRLskiIiJqJVlEREStJIuIiKiVZBEREbWSLCIiolaSRURE1EqyiIiIWkkWERFRq21PcEe028QZFw+6f8nJBw1TJBEbvtQsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJXnLPox2Pj9jN2PiNEoNYuIiKiVZBEREbWSLCIiolaSRURE1OpIspC0RNJCSQskzStl20iaI+n28rl1KZek0yQtlnSTpN06EXNExGjWyZrFG2xPtj2lbM8ALrc9Cbi8bAMcAEwqy3Tg9GGPNCJilOumZqhDgJllfSbw1pbyH7hyDTBW0vgOxBcRMWp1KlkYuEzSfEnTS9m2tpeX9XuAbcv69sDdLecuLWV/Q9J0SfMkzVuxYkW74o6IGJU69VDe3raXSXouMEfS71p32rYkr80FbZ8BnAEwZcqUtTo3IiIG15Gahe1l5fM+4GfAHsC9vc1L5fO+cvgyYIeW0yeUsoiIGCbDniwkPVPSVr3rwP7AzcAsYFo5bBrw87I+CziijIraC3i4pbkqIiKGQSeaobYFfiap9/4/tn2JpLnABZKOAu4CDi3HzwYOBBYDjwNHDn/IERGj27AnC9t3AK/sp/wBYN9+yg0cPQyhRUTEALpp6GxERHSpJIuIiKiV91lE9GOwd5pA3msSo09qFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolYkEI4bZYJMUZoLC6FapWURERK0ki4iIqJVkERERtZIsIiKiVjq4I0aQvMEvOiU1i4iIqDVikoWkqZJuk7RY0oxOxxMRMZqMiGYoSWOAbwH7AUuBuZJm2b6ls5FFbDjSxBWDGRHJAtgDWGz7DgBJ5wOHAEkWESNAOx9EzEOOw0O2Ox1DLUlvB6ba/kDZfi+wp+2PtBwzHZheNl8E3DbsgQ5uHHB/p4NYCyMp3pEUK4yseEdSrDCy4u3GWJ9vu6e/HSOlZlHL9hnAGZ2OYyCS5tme0uk4mhpJ8Y6kWGFkxTuSYoWRFe9IihVGTgf3MmCHlu0JpSwiIobBSEkWc4FJknaStClwGDCrwzFFRIwaI6IZyvZqSR8BLgXGAGfbXtThsNZW1zaRDWAkxTuSYoWRFe9IihVGVrwjKdaR0cEdERGdNVKaoSIiooOSLCIiolaSRZtJ2kHSFZJukbRI0rGdjqmOpDGSbpB0UadjqSNprKQLJf1O0q2SXtPpmAYi6Z/Kv4GbJZ0nafNOx9RK0tmS7pN0c0vZNpLmSLq9fG7dyRhbDRDvV8q/hZsk/UzS2A6G+Ff9xdqy7zhJljSuE7E1lWTRfquB42zvCuwFHC1p1w7HVOdY4NZOB9HQ14FLbL8YeCVdGrek7YFjgCm2X0Y1UOOwzkb1NOcAU/uUzQAutz0JuLxsd4tzeHq8c4CX2X4F8N/A8cMd1ADO4emxImkHYH/g98Md0NpKsmgz28ttX1/WH6X6YbZ9Z6MamKQJwEHA9zodSx1JzwZeD5wFYPsvth/qaFCD2xjYQtLGwDOAP3Q4nr9h+yrgwT7FhwAzy/pM4K3DGdNg+ovX9mW2V5fNa6ieyeq4Af5sAU4FPgl0/UijJIthJGki8Crg2g6HMpivUf3jfbLDcTSxE7AC+H5pNvuepGd2Oqj+2F4GfJXqN8jlwMO2L+tsVI1sa3t5Wb8H2LaTwayl9wP/2ekgBiLpEGCZ7Rs7HUsTSRbDRNKWwE+Aj9l+pNPx9EfSwcB9tud3OpaGNgZ2A063/SrgMbqrmeSvSlv/IVQJbjvgmZLe09mo1o6rcfZd/xswgKTPUDUBn9vpWPoj6RnAp4HPdjqWppIshoGkTagSxbm2f9rpeAbxOuAtkpYA5wNvlPSjzoY0qKXAUtu9NbULqZJHN3oTcKftFbafAH4KvLbDMTVxr6TxAOXzvg7HU0vS+4CDgXe7ex8kewHVLw43lv9vE4DrJT2vo1ENIsmizSSJqk39VtundDqewdg+3vYE2xOpOl9/abtrf/u1fQ9wt6QXlaJ96d5p638P7CXpGeXfxL50aWd8H7OAaWV9GvDzDsZSS9JUqmbUt9h+vNPxDMT2QtvPtT2x/H9bCuxW/k13pSSL9nsd8F6q39IXlOXATge1AfkocK6km4DJwP/rbDj9K7WfC4HrgYVU//e6aroHSecBvwVeJGmppKOAk4H9JN1OVTs6uZMxthog3m8CWwFzyv+173Q0yGKAWEeUTPcRERG1UrOIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkESOepJVtuObk1iHOkk6U9PH1uN47yqy4VwxNhOscx5Jun900ulOSRUT/JgND+TzMUcAHbb9hCK8ZMWySLGKDIukTkuaW9xl8rpRNLL/Vn1neJ3GZpC3Kvt3LsQvKuxBulrQp8HngnaX8neXyu0q6UtIdko4Z4P6HS1pYrvPlUvZZYG/gLElf6XP8eElXlfvcLOnvSvnpkuaVeD/XcvwSSV8qx8+TtJukSyX9j6QPlWP2Kde8WNJtkr4j6Wn/1yW9R9J15VrfVfUekzGSzimxLJT0T+v5VxIbCttZsozoBVhZPveneipaVL8IXUQ1hflEqknlJpfjLgDeU9ZvBl5T1k8Gbi7r7wO+2XKPE4HfAJsB44AHgE36xLEd1bQePVSTHP4SeGvZdyXVuyz6xn4c8JmyPgbYqqxv01J2JfCKsr0E+HBZPxW4ieqJ5R7g3lK+D/BnYOdy/hzg7S3njwNeAvxH73cAvg0cAbwamNMS39hO//1m6Y4lNYvYkOxflhuoptV4MTCp7LvT9oKyPh+YWN6itpXt35byH9dc/2Lbq2zfTzWhXt/puncHrnQ1WWDvjKevr7nmXOBISScCL3f1zhOAQyVdX77LS4HWF2bNKp8LgWttP2p7BbBKT70Z7jrbd9heA5xHVbNptS9VYpgraUHZ3hm4A9hZ0jfKPEtdOUNyDL+NOx1AxBAS8CXb3/2bwuo9IqtaitYAW6zD9fteY73//9i+StLrqV44dY6kU4D/Aj4O7G77j5LOAVpfwdobx5N9YnqyJaa+8/j03RYw0/bT3iQn6ZXAm4EPAYdSvRciRrnULGJDcinw/vLuECRtL+m5Ax3s6q16j0rasxS1vub0UarmnbVxHfC/JI2TNAY4HPjVYCdIej5V89GZVG8n3A14FtW7OR6WtC1wwFrGAbCHpJ1KX8U7gav77L8ceHvvn4+qd20/v4yU2sj2T4B/pnunfI9hlppFbDBsXybpJcBvq1nAWQm8h6oWMJCjgDMlPUn1g/3hUn4FMKM00Xyp4f2XS5pRzhVVs1XdlN77AJ+Q9ESJ9wjbd0q6AfgdcDfw6yb372Mu1Qysu5R4ftYn1lsk/TNwWUkoTwBHA3+ievNg7y+S3fIO6+iwzDobo5qkLW2vLOszgPG2j+1wWOtF0j7Ax20f3OFQYgOSmkWMdgdJOp7q/8JdVKOgIqKP1CwiIqJWOrgjIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiav1/kOw4nIchTGMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "questions_len = [len(s.split()) for s in source_data['Q']]\n",
    "answers_len = [len(s.split()) for s in source_data['A']]\n",
    "\n",
    "print('Qestion의 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('Qestion의 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('Qestion의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('Answer의 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('Answer의 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('Answer의 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('Questions')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('Answers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4d048",
   "metadata": {},
   "source": [
    "## Step3. 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e887b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66260e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ac8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [21842]\n",
      "END_TOKEN의 번호 : [21843]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0f49ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21844\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60d89f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 3번째 질문 샘플: [9607, 1944, 39]\n",
      "정수 인코딩 후의 3번째 답변 샘플: [2598, 456, 86, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 3번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 3번째 질문 샘플: {}'.format(tokenizer.encode(questions[2])))\n",
    "print('정수 인코딩 후의 3번째 답변 샘플: {}'.format(tokenizer.encode(answers[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8763b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "#샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 21\n",
    "print(MAX_LENGTH)\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 25 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 25으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bc8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 21844\n",
      "필터링 후의 질문 샘플 개수: 11821\n",
      "필터링 후의 답변 샘플 개수: 11821\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35610294",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 2000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3e4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49726b37",
   "metadata": {},
   "source": [
    "### 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14edea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcef11",
   "metadata": {},
   "source": [
    "### 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf66a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44050504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975de03",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a534442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238ccbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bed6fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b439d",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8319478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "637065a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4a95525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3fbd1",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f596aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21844, 256)\n",
      "(1, 21844, 256)\n",
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    6646272     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    7173632     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 21844)  5613908     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,433,812\n",
      "Trainable params: 19,433,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc63ab1",
   "metadata": {},
   "source": [
    "### 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06839c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e42ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c54d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177cb0d",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8668f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 19s 65ms/step - loss: 2.6601 - accuracy: 0.0606\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 12s 65ms/step - loss: 2.1011 - accuracy: 0.0973\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.6578 - accuracy: 0.0985\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.4987 - accuracy: 0.1021\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.3989 - accuracy: 0.1074\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.3077 - accuracy: 0.1121\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.2077 - accuracy: 0.1188\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 1.0968 - accuracy: 0.1282\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.9736 - accuracy: 0.1416\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.8425 - accuracy: 0.1587\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.7062 - accuracy: 0.1756\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.5705 - accuracy: 0.1926\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.4416 - accuracy: 0.2102\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.3283 - accuracy: 0.2270\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 12s 65ms/step - loss: 0.2312 - accuracy: 0.2438\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.1605 - accuracy: 0.2571\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.1092 - accuracy: 0.2666\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0758 - accuracy: 0.2722\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0588 - accuracy: 0.2745\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0503 - accuracy: 0.2753\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 12s 65ms/step - loss: 0.0450 - accuracy: 0.2761\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0417 - accuracy: 0.2765\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0380 - accuracy: 0.2773\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0315 - accuracy: 0.2784\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0284 - accuracy: 0.2792\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0247 - accuracy: 0.2800\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0223 - accuracy: 0.2807\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0197 - accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0178 - accuracy: 0.2817\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 12s 64ms/step - loss: 0.0179 - accuracy: 0.2818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd20b41670>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaebce",
   "metadata": {},
   "source": [
    "### 대화해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efcc6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "debb5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c11e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 배고파\n",
      "출력 : 뭐 좀 챙겨드세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뭐 좀 챙겨드세요 . '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('배고파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d0a3564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 더워\n",
      "출력 : 시원한 물이라도 한 잔 드세요~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'시원한 물이라도 한 잔 드세요~'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('너무 더워')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fae65fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 최신 영화 추천해드립니다 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'최신 영화 추천해드립니다 . '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('어떤 영화 좋아해?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
